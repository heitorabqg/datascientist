{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heitorabqg/datascientist/blob/master/PSI5892_FashionMNIST_1128.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26fxjoVADscQ"
      },
      "source": [
        "Para abrir o notebook no Google Colab, altere o domínio `github.com` para `githubtocolab.com`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u5Vt9k5TQi-"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "Para praticar programação, é importante que você erre, leia as mensagens de erro e tente corrigí-los.\n",
        "    \n",
        "Dessa forma, no Google Colab, é importante que você DESATIVE OS RECURSOS DE AUTOCOMPLETAR:\n",
        "\n",
        "- Menu Ferramentas -> Configurações\n",
        "- Na janela que é aberta:\n",
        "  - Seção Editor -> Desativar \"Mostrar sugestões de preenchimento de código com base no contexto\"\n",
        "  - Seção Assistência de IA -> Desabilitar itens\n",
        "\n",
        "Na versão em inglês:\n",
        "\n",
        "- Menu Tools -> Settings\n",
        "- Na janela que é aberta:\n",
        "  - Seção Editor -> Desativar \"Show context-powered code completions\"\n",
        "  - Seção AI Assistance -> Desabilitar itens\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c04thLl8Dzh4"
      },
      "source": [
        "# PSI5892 - Aula de Exercícios\n",
        "\n",
        "# MLP com PyTorch\n",
        "\n",
        "Neste exercício vamos treinar uma rede MLP usando o *framework* PyTorch, para a solução de um problema de classificação usando o banco de dados [Fashion MNIST](https://arxiv.org/abs/1708.07747), que contém 70000 imagens 28x28 de peças de vestuário distribuídas em 10 classes, divididas em um conjunto de treinamento com 60000 imagens e um de teste com 10000.\n",
        "\n",
        "Os dados estão disponíveis na biblioteca `torchvision` e os objetos `DataLoader` podem ser criados com:\n",
        "\n",
        "``` python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "dir_data = \"~/temp\"\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.FashionMNIST(\n",
        "        dir_data,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(            \n",
        "            [transforms.ToTensor()]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=Nb,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.FashionMNIST(\n",
        "        dir_data,\n",
        "        train=False,\n",
        "        transform=transforms.Compose(            \n",
        "            [transforms.ToTensor()]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=Nb_test,\n",
        "    shuffle=True,\n",
        ")\n",
        "```\n",
        "\n",
        "Vale notar alguns detalhes sobre o código anterior:\n",
        "\n",
        " - o `DataLoader` de treinamento é criado com `train=True` e o de teste, com `train=False`, o que garante que não haja dados em comum entre os dois conjuntos;\n",
        " - `Nb` e `Nb_test` representam os tamanhos dos mini *batches* de treino e teste;\n",
        " - É feita a configuração de uma transformação de dados ao carregá-los. Para isso, é criado um objeto do tipo `transforms.Compose`, que permite encadear uma série de transformações a serem aplicadas às imagens, durante o carregamento. Nesse caso, a transformação tem uma única etapa que consistem em converter os valores obtidos para um tensor do PyTorch.\n",
        "\n",
        "Para ver algumas imagens do banco de dados usando o DataLoader criado, pode ser utilizado o seguinte código:\n",
        "\n",
        "``` python\n",
        "plt.figure(figsize=(16, 6))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    image, _ = train_loader.dataset.__getitem__(i)\n",
        "    plt.imshow(image.squeeze().numpy())\n",
        "    plt.axis('off');\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AqCDV8kTQi_"
      },
      "source": [
        "# Exercício 1\n",
        "\n",
        "Implemente uma rede MLP para classificação de imagens do conjunto Fashion MNIST usando o PyTorch. Lembre-se que trata-se de um problema de classificação multiclasse e utilize a arquitetura mais adequada.\n",
        "\n",
        "No caso de usar a entropia cruzada, vale notar que a função custo `CrossEntropyLoss` espera comparar um vetor de $C$ posições com um número de $0$ a $C-1$, conforme descrito na [documentação](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Além disso, é esperado que os elementos do vetor representem a *evidência*, ou seja os valores chamados de *logits*, que não são normalizados e podem valer de $-\\infty$ a $\\infty$. Por isso, na saída da rede, não é usada a função *Softmax*.\n",
        "\n",
        "Por fim, avalie o modelo treinado em termos de acurácia (número de acertos dividido pelo número de testes) e busque variar os hiperparâmetros da rede a fim de obter uma acurácia próxima a 85%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBhys0knTQjA"
      },
      "source": [
        "## Resolução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8n7UqbHTTQjA",
        "outputId": "7b869b3a-94ff-4097-f5d8-d027865d8d73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######## TREINAMENTO ########\n",
            "Época 1 - Loss: 0.5076 - Acurácia: 84.91%\n",
            "Época 2 - Loss: 0.3642 - Acurácia: 85.23%\n",
            "Época 3 - Loss: 0.3231 - Acurácia: 87.47%\n",
            "Época 4 - Loss: 0.3005 - Acurácia: 87.06%\n",
            "Época 5 - Loss: 0.2806 - Acurácia: 87.74%\n",
            "Época 6 - Loss: 0.2649 - Acurácia: 87.47%\n",
            "Época 7 - Loss: 0.2531 - Acurácia: 88.60%\n",
            "Época 8 - Loss: 0.2411 - Acurácia: 88.58%\n",
            "Época 9 - Loss: 0.2297 - Acurácia: 88.77%\n",
            "Época 10 - Loss: 0.2198 - Acurácia: 89.14%\n",
            "Época 11 - Loss: 0.2111 - Acurácia: 89.61%\n",
            "Época 12 - Loss: 0.2027 - Acurácia: 89.38%\n",
            "Época 13 - Loss: 0.1922 - Acurácia: 89.22%\n",
            "Época 14 - Loss: 0.1859 - Acurácia: 88.85%\n",
            "Época 15 - Loss: 0.1772 - Acurácia: 89.15%\n",
            "Época 16 - Loss: 0.1694 - Acurácia: 88.93%\n",
            "Época 17 - Loss: 0.1618 - Acurácia: 89.01%\n",
            "Época 18 - Loss: 0.1608 - Acurácia: 88.75%\n",
            "Época 19 - Loss: 0.1516 - Acurácia: 89.27%\n",
            "Época 20 - Loss: 0.1473 - Acurácia: 89.71%\n",
            "\n",
            "######## TESTE ########\n",
            "\n",
            "Acurácia no teste: 89.71%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "Nb = 100\n",
        "\n",
        "Nb_test = 100\n",
        "lr = 0.001\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "dir_data = \"./data\"\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    datasets.FashionMNIST(\n",
        "        dir_data,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    ),\n",
        "    batch_size=Nb,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    datasets.FashionMNIST(\n",
        "        dir_data,\n",
        "        train=False,\n",
        "        transform=transform\n",
        "    ),\n",
        "    batch_size=Nb_test,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.net(x)\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for X, y in loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in loader:\n",
        "            logits = model(X)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "print(\"\\n######## TREINAMENTO ########\")\n",
        "for epoch in range(epochs):\n",
        "    loss = train(model, train_loader)\n",
        "    acc = evaluate(model, test_loader)\n",
        "    print(f\"Época {epoch+1} - Loss: {loss:.4f} - Acurácia: {acc*100:.2f}%\")\n",
        "\n",
        "\n",
        "print(\"\\n######## TESTE ########\")\n",
        "\n",
        "acc_final = evaluate(model, test_loader)\n",
        "print(f\"\\nAcurácia no teste: {acc_final*100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}